{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Neural Networks\n",
    "##### Structure of a Neural Network:\n",
    "- **Input Layer**: Takes input features (e.g., pixels in an image).\n",
    "- **Hidden Layers**: Learn complex patterns from data.\n",
    "- **Output Layer**: Provides the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "  Input Layer    Hidden Layer    Output Layer\n",
    "      O               O               O\n",
    "    /   \\           /   \\           /\n",
    "  O       O -----> O     O -----> O  \n",
    "    \\   /           \\   /          \n",
    "      O               O  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a Simple Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (Hours Studied, Sleep Hours)\n",
    "X = np.array([[1, 2], [2, 3], [3, 5], [4, 2], [5, 6], [6, 7], [7, 8], [8, 7]])\n",
    "# Output (1 = Pass, 0 = Fail)\n",
    "y = np.array([[0], [0], [1], [0], [1], [1], [1], [1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Activation Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid (for Backpropagation)\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Initialize Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "weights = np.random.rand(2, 1)  # Two input features, one output\n",
    "bias = np.random.rand(1)\n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Neural Network (Forward + Backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3564\n",
      "Epoch 1000, Loss: 0.0105\n",
      "Epoch 2000, Loss: 0.0057\n",
      "Epoch 3000, Loss: 0.0039\n",
      "Epoch 4000, Loss: 0.0029\n",
      "Epoch 5000, Loss: 0.0023\n",
      "Epoch 6000, Loss: 0.0019\n",
      "Epoch 7000, Loss: 0.0017\n",
      "Epoch 8000, Loss: 0.0015\n",
      "Epoch 9000, Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000  # Number of iterations\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    Z = np.dot(X, weights) + bias\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    # Compute Error\n",
    "    error = y - A\n",
    "\n",
    "    # Backpropagation\n",
    "    dZ = error * sigmoid_derivative(A)  # Gradient of Loss w.r.t Z\n",
    "    weights += np.dot(X.T, dZ) * learning_rate  # Update Weights\n",
    "    bias += np.sum(dZ) * learning_rate  # Update Bias\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(error ** 2)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Probability of Passing): [[0.8900576]]\n"
     ]
    }
   ],
   "source": [
    "# Predict for new data\n",
    "new_student = np.array([[4, 5]])  # 4 study hours, 5 sleep hours\n",
    "prediction = sigmoid(np.dot(new_student, weights) + bias)\n",
    "print(\"Prediction (Probability of Passing):\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Deep Learning Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (Hours Studied, Sleep Hours)\n",
    "X = np.array([[1, 2], [2, 3], [3, 5], [4, 2], [5, 6], [6, 7], [7, 8], [8, 7]], dtype=np.float32)\n",
    "# Output (1 = Pass, 0 = Fail)\n",
    "y = np.array([[0], [0], [1], [0], [1], [1], [1], [1]], dtype=np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 4)  # 2 input features → 4 neurons in the hidden layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.output = nn.Linear(4, 1)  # 4 hidden neurons → 1 output neuron\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create model instance\n",
    "model = NeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss (for binary classification)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer with learning rate 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7094\n",
      "Epoch 100, Loss: 0.2709\n",
      "Epoch 200, Loss: 0.0643\n",
      "Epoch 300, Loss: 0.0275\n",
      "Epoch 400, Loss: 0.0154\n",
      "Epoch 500, Loss: 0.0098\n",
      "Epoch 600, Loss: 0.0067\n",
      "Epoch 700, Loss: 0.0049\n",
      "Epoch 800, Loss: 0.0037\n",
      "Epoch 900, Loss: 0.0029\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000  # Number of training iterations\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Probability of Passing): [[0.9874164]]\n"
     ]
    }
   ],
   "source": [
    "# Test data (Predict if a student who studied 4 hours and slept 5 hours will pass)\n",
    "new_student = torch.tensor([[4, 5]], dtype=torch.float32)\n",
    "prediction = model(new_student).detach().numpy()\n",
    "print(\"Prediction (Probability of Passing):\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
